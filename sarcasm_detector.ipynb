{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b4ca886860e4edca722bf52c03822b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e4c223b87c94fcbaceee9c816bfd4b0",
              "IPY_MODEL_6f9bf97215574280b8c45a3b00f81c27",
              "IPY_MODEL_30e1464796eb440db27904e7c2f2c8e3"
            ],
            "layout": "IPY_MODEL_e8ceb99d8b044a63825a2c4d11b3cf39"
          }
        },
        "5e4c223b87c94fcbaceee9c816bfd4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8b955f13b14e0d82cf45c33610d85c",
            "placeholder": "​",
            "style": "IPY_MODEL_a4627ca593e146b49be722e7c4798987",
            "value": "Map: 100%"
          }
        },
        "6f9bf97215574280b8c45a3b00f81c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2970740e9e204a158609b14f90834e91",
            "max": 22895,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_951b2b6171df44489d0cd35e360f2766",
            "value": 22895
          }
        },
        "30e1464796eb440db27904e7c2f2c8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0cd03be4e04e7b84ae4a146060a52a",
            "placeholder": "​",
            "style": "IPY_MODEL_243f7332af9f43c893329a805288c3b9",
            "value": " 22895/22895 [00:30&lt;00:00, 890.20 examples/s]"
          }
        },
        "e8ceb99d8b044a63825a2c4d11b3cf39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8b955f13b14e0d82cf45c33610d85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4627ca593e146b49be722e7c4798987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2970740e9e204a158609b14f90834e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951b2b6171df44489d0cd35e360f2766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d0cd03be4e04e7b84ae4a146060a52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243f7332af9f43c893329a805288c3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071948c453ee41c29ac633b8715082da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6876cce078f9438fa7558a19bfc838ae",
              "IPY_MODEL_14d77db47ff84a6cbfd1a883f37a15ec",
              "IPY_MODEL_8aeb21d6bf4148ca93863a59784dc70a"
            ],
            "layout": "IPY_MODEL_a227ef33be054cc7a46708ed2978994c"
          }
        },
        "6876cce078f9438fa7558a19bfc838ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7794c7360b9f4b4487254b9208407247",
            "placeholder": "​",
            "style": "IPY_MODEL_4814c18265f64fb38627d829334349af",
            "value": "Map: 100%"
          }
        },
        "14d77db47ff84a6cbfd1a883f37a15ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20af8f96a98f4a0596270449026c38a2",
            "max": 5724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70623c597297477da249fb53a15b7e7e",
            "value": 5724
          }
        },
        "8aeb21d6bf4148ca93863a59784dc70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b19d3c9c5554a1e929fc98bb48523aa",
            "placeholder": "​",
            "style": "IPY_MODEL_636fc3dc0ec94561a1a9b4ce04017ed5",
            "value": " 5724/5724 [00:03&lt;00:00, 1573.50 examples/s]"
          }
        },
        "a227ef33be054cc7a46708ed2978994c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7794c7360b9f4b4487254b9208407247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4814c18265f64fb38627d829334349af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20af8f96a98f4a0596270449026c38a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70623c597297477da249fb53a15b7e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b19d3c9c5554a1e929fc98bb48523aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636fc3dc0ec94561a1a9b4ce04017ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1> Sarcasm detection project </h1>\n",
        "\n"
      ],
      "metadata": {
        "id": "mhWMaPHnwKzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> TF-IDF baseline </h2>"
      ],
      "metadata": {
        "id": "3PeAV0WSwQ5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR_0aAHfuZhW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Graphic settings\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Sarcasm_Headlines_Dataset_v2.json'\n",
        "\n",
        "try:\n",
        "    df = pd.read_json(file_path, lines=True)\n",
        "    print(\"Dataset caricato con successo!\")\n",
        "    print(f\"Dimensioni del dataset: {df.shape}\")\n",
        "except ValueError:\n",
        "    print(\"Errore: Assicurati di aver caricato il file JSON e che il nome sia corretto.\")\n",
        "\n",
        "# Visualize first rows\n",
        "df.head()"
      ],
      "metadata": {
        "id": "WyB1QVYqwovg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class balancements\n",
        "print(df['is_sarcastic'].value_counts())\n",
        "\n",
        "sns.countplot(x='is_sarcastic', data=df)\n",
        "plt.title('Class distributions (0 = Non Sarcastic, 1 = Sarcastic)')\n",
        "plt.show()\n",
        "\n",
        "# Check null values\n",
        "print(\"\\nNull values in datasets:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "0BV7gy8AwuJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definizione X (features) e y (target)\n",
        "X = df['headline']\n",
        "y = df['is_sarcastic']\n",
        "\n",
        "# Split 80% training, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "GSUURNpPw2SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization initialization\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=10000, ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transformation on training set, transformazion only on test set\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(\"Vectorization completed.\")\n",
        "print(f\"Training matrix shape: {X_train_tfidf.shape}\")"
      ],
      "metadata": {
        "id": "U_1aJauEw6Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Training\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"Modello addestrato.\")"
      ],
      "metadata": {
        "id": "Y88NfiWGw--N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predition on test set\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Metrics calculation\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy della Baseline: {acc:.4f}\\n\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Non Sarcastico', 'Sarcastico'], yticklabels=['Non Sarcastico', 'Sarcastico'])\n",
        "plt.ylabel('Reale')\n",
        "plt.xlabel('Predetto')\n",
        "plt.title('Matrice di Confusione')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cscx4eJVxFyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sarcasm(text):\n",
        "    vec = tfidf.transform([text])\n",
        "    prediction = model.predict(vec)\n",
        "    probability = model.predict_proba(vec)[0][1]\n",
        "    label = \"SARCASTICO\" if prediction[0] == 1 else \"NON SARCASTICO\"\n",
        "    return label, probability\n",
        "\n",
        "# Esempi\n",
        "sample_1 = \"Local man discovers water is wet\"\n",
        "sample_2 = \"My favorite hobby is sitting in a two-hour meeting that could have been a single sentence email.\"\n",
        "sample_3 = \"Politician promises to fix everything in 24 hours\"\n",
        "\n",
        "print(f\"'{sample_1}' -> {predict_sarcasm(sample_1)}\")\n",
        "print(f\"'{sample_2}' -> {predict_sarcasm(sample_2)}\")\n",
        "print(f\"'{sample_3}' -> {predict_sarcasm(sample_3)}\")"
      ],
      "metadata": {
        "id": "HA5VN4Ec16OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>DistilBERT</h2>\n"
      ],
      "metadata": {
        "id": "vB3tredX2_1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets accelerate scikit-learn"
      ],
      "metadata": {
        "id": "CR8BP1uv3E4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Verifica GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device in uso: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"ATTENZIONE: Stai usando la CPU. Attiva la GPU in Runtime -> Cambia tipo di runtime -> T4 GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ubj-cqR3jgh",
        "outputId": "914bfcd3-6824-4340-9c75-40c1e802a075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device in uso: cuda\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "file_path = 'Sarcasm_Headlines_Dataset_v2.json' # O la versione v2\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "\n",
        "# Rename columns for huggingface compatibility\n",
        "# Il modello si aspetta 'labels' per il target e 'text' (opzionale, ma utile per chiarezza)\n",
        "df = df.rename(columns={'is_sarcastic': 'labels', 'headline': 'text'})\n",
        "df = df[['text', 'labels']]\n",
        "\n",
        "# Split Train/Test (80/20)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'])\n",
        "\n",
        "# Conversion in huggingface object dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKaq0s453nrM",
        "outputId": "831dae8c-8abd-4bd6-e29d-ab58450047ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 22895\n",
            "Test samples: 5724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search specific tokenizer for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# Apply tokenization on all dataset\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Remove original text columns and pandas index; keep tensors only.\n",
        "tokenized_train = tokenized_train.remove_columns(['text', '__index_level_0__'])\n",
        "tokenized_test = tokenized_test.remove_columns(['text', '__index_level_0__'])\n",
        "\n",
        "# Set the format for PyTorch\n",
        "tokenized_train.set_format(\"torch\")\n",
        "tokenized_test.set_format(\"torch\")\n",
        "\n",
        "print(\"Tokenizzazione completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "6b4ca886860e4edca722bf52c03822b2",
            "5e4c223b87c94fcbaceee9c816bfd4b0",
            "6f9bf97215574280b8c45a3b00f81c27",
            "30e1464796eb440db27904e7c2f2c8e3",
            "e8ceb99d8b044a63825a2c4d11b3cf39",
            "7a8b955f13b14e0d82cf45c33610d85c",
            "a4627ca593e146b49be722e7c4798987",
            "2970740e9e204a158609b14f90834e91",
            "951b2b6171df44489d0cd35e360f2766",
            "8d0cd03be4e04e7b84ae4a146060a52a",
            "243f7332af9f43c893329a805288c3b9",
            "071948c453ee41c29ac633b8715082da",
            "6876cce078f9438fa7558a19bfc838ae",
            "14d77db47ff84a6cbfd1a883f37a15ec",
            "8aeb21d6bf4148ca93863a59784dc70a",
            "a227ef33be054cc7a46708ed2978994c",
            "7794c7360b9f4b4487254b9208407247",
            "4814c18265f64fb38627d829334349af",
            "20af8f96a98f4a0596270449026c38a2",
            "70623c597297477da249fb53a15b7e7e",
            "8b19d3c9c5554a1e929fc98bb48523aa",
            "636fc3dc0ec94561a1a9b4ce04017ed5"
          ]
        },
        "id": "gR4eCNy23rgd",
        "outputId": "cb535a90-6b1d-45f1-c10e-785f7a378971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/22895 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b4ca886860e4edca722bf52c03822b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5724 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "071948c453ee41c29ac633b8715082da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizzazione completata.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "print(\"Model loaded on GPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY5-x4TP3xvG",
        "outputId": "8e46cf30-c6a1-4d4c-8ae2-132498ed448a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modello caricato su GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "mVEzwcQT31ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory\n",
        "    num_train_epochs=2,              # Number of training epochs\n",
        "    per_device_train_batch_size=16,  # Batch size per device during training\n",
        "    per_device_eval_batch_size=32,   # Batch size for evaluation\n",
        "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # Strength of weight decay (regularization)\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"epoch\",           # Evaluation is performed at the end of each epoch\n",
        "    save_strategy=\"epoch\",           # Save is performed at the end of each epoch\n",
        "    load_best_model_at_end=True,     # Load the best model found during training at the end\n",
        "    fp16=True,                       # Use mixed precision (significantly faster on T4 GPUs)\n",
        "    report_to=\"none\"                 # Disable third-party logging (e.g., wandb, mlflow)\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "qa4syZJe4JEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install optuna if not already present\n",
        "!pip install -q optuna\n",
        "\n",
        "import optuna\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer, DistilBertForSequenceClassification\n",
        "\n",
        "def model_init():\n",
        "    return DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',\n",
        "        num_labels=2\n",
        "    ).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "#Define the hyperparameter search space\n",
        "def hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
        "    }\n",
        "\n",
        "# Base Training Arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir='./results_search',\n",
        "    eval_strategy=\"epoch\",       # <--- Updated parameter name\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=True,                   # Optimized for T4 GPU\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer with model_init\n",
        "trainer = Trainer(\n",
        "    model=None,\n",
        "    model_init=model_init,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Run the search\n",
        "print(\"Starting Hyperparameter Search...\")\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    hp_space=hp_space,\n",
        "    backend=\"optuna\",\n",
        "    n_trials=10\n",
        ")\n",
        "\n",
        "print(\"\\nBest Hyperparameters found:\")\n",
        "print(best_run)\n",
        "\n",
        "#Update the trainer with the best values for the final training\n",
        "for n, v in best_run.hyperparameters.items():\n",
        "    setattr(trainer.args, n, v)\n",
        "\n",
        "print(\"\\nReady to train with best parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oCK2Ya5AXVuK",
        "outputId": "8e34650e-96b4-40ca-e20d-0bcaafadc859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1890729201.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-12-16 18:34:34,054] A new study created in memory with name: no-name-9cf04a28-88f8-4bb8-9dd8-d75edfe39a5e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Hyperparameter Search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20251216_183502-809u137m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2864' max='2864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2864/2864 05:40, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.220300</td>\n",
              "      <td>0.198157</td>\n",
              "      <td>0.923131</td>\n",
              "      <td>0.917541</td>\n",
              "      <td>0.938291</td>\n",
              "      <td>0.897690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.089600</td>\n",
              "      <td>0.244081</td>\n",
              "      <td>0.928022</td>\n",
              "      <td>0.923505</td>\n",
              "      <td>0.935314</td>\n",
              "      <td>0.911991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.050600</td>\n",
              "      <td>0.347540</td>\n",
              "      <td>0.924528</td>\n",
              "      <td>0.918120</td>\n",
              "      <td>0.950177</td>\n",
              "      <td>0.888155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.011600</td>\n",
              "      <td>0.412178</td>\n",
              "      <td>0.928721</td>\n",
              "      <td>0.923164</td>\n",
              "      <td>0.948897</td>\n",
              "      <td>0.898790</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-16 18:40:49,831] Trial 0 finished with value: 3.6995715266234623 and parameters: {'learning_rate': 4.4347502871907344e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.054726515561503236}. Best is trial 0 with value: 3.6995715266234623.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▃█</td></tr><tr><td>eval/f1</td><td>▁█▂█</td></tr><tr><td>eval/loss</td><td>▁▃▆█</td></tr><tr><td>eval/precision</td><td>▂▁█▇</td></tr><tr><td>eval/recall</td><td>▄█▁▄</td></tr><tr><td>eval/runtime</td><td>▁▂██</td></tr><tr><td>eval/samples_per_second</td><td>█▇▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92872</td></tr><tr><td>eval/f1</td><td>0.92316</td></tr><tr><td>eval/loss</td><td>0.41218</td></tr><tr><td>eval/precision</td><td>0.9489</td></tr><tr><td>eval/recall</td><td>0.89879</td></tr><tr><td>eval/runtime</td><td>7.2981</td></tr><tr><td>eval/samples_per_second</td><td>784.311</td></tr><tr><td>eval/steps_per_second</td><td>98.107</td></tr><tr><td>total_flos</td><td>3032841092229120.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "You can sync this run to the cloud by running:<br><code>wandb sync /content/wandb/offline-run-20251216_183502-809u137m<code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/offline-run-20251216_183502-809u137m/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20251216_184050-wpttboup</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2864' max='2864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2864/2864 05:31, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.252800</td>\n",
              "      <td>0.230235</td>\n",
              "      <td>0.905486</td>\n",
              "      <td>0.899536</td>\n",
              "      <td>0.911211</td>\n",
              "      <td>0.888155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.163300</td>\n",
              "      <td>0.242188</td>\n",
              "      <td>0.905136</td>\n",
              "      <td>0.896037</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.858086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.140900</td>\n",
              "      <td>0.239977</td>\n",
              "      <td>0.914221</td>\n",
              "      <td>0.907932</td>\n",
              "      <td>0.929010</td>\n",
              "      <td>0.887789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.098000</td>\n",
              "      <td>0.269993</td>\n",
              "      <td>0.915618</td>\n",
              "      <td>0.909125</td>\n",
              "      <td>0.933539</td>\n",
              "      <td>0.885955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-16 18:46:24,302] Trial 1 finished with value: 3.6442382410958034 and parameters: {'learning_rate': 1.0682295806539672e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 32, 'weight_decay': 0.07433754097425414}. Best is trial 0 with value: 3.6995715266234623.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▇█</td></tr><tr><td>eval/f1</td><td>▃▁▇█</td></tr><tr><td>eval/loss</td><td>▁▃▃█</td></tr><tr><td>eval/precision</td><td>▁█▆▇</td></tr><tr><td>eval/recall</td><td>█▁█▇</td></tr><tr><td>eval/runtime</td><td>█▁▂▄</td></tr><tr><td>eval/samples_per_second</td><td>▁█▇▅</td></tr><tr><td>eval/steps_per_second</td><td>▁█▇▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.91562</td></tr><tr><td>eval/f1</td><td>0.90913</td></tr><tr><td>eval/loss</td><td>0.26999</td></tr><tr><td>eval/precision</td><td>0.93354</td></tr><tr><td>eval/recall</td><td>0.88596</td></tr><tr><td>eval/runtime</td><td>7.0139</td></tr><tr><td>eval/samples_per_second</td><td>816.098</td></tr><tr><td>eval/steps_per_second</td><td>102.084</td></tr><tr><td>total_flos</td><td>3032841092229120.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "You can sync this run to the cloud by running:<br><code>wandb sync /content/wandb/offline-run-20251216_184050-wpttboup<code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/offline-run-20251216_184050-wpttboup/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20251216_184625-na7h5i8i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4293' max='4293' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4293/4293 05:13, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.230200</td>\n",
              "      <td>0.209130</td>\n",
              "      <td>0.916492</td>\n",
              "      <td>0.911053</td>\n",
              "      <td>0.924821</td>\n",
              "      <td>0.897690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.118900</td>\n",
              "      <td>0.325715</td>\n",
              "      <td>0.907582</td>\n",
              "      <td>0.896981</td>\n",
              "      <td>0.956395</td>\n",
              "      <td>0.844518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.325591</td>\n",
              "      <td>0.922432</td>\n",
              "      <td>0.916792</td>\n",
              "      <td>0.937524</td>\n",
              "      <td>0.896956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-16 18:51:41,283] Trial 2 finished with value: 3.673703787867411 and parameters: {'learning_rate': 1.5009200258446927e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'weight_decay': 0.07460999453654459}. Best is trial 0 with value: 3.6995715266234623.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅▁█</td></tr><tr><td>eval/f1</td><td>▆▁█</td></tr><tr><td>eval/loss</td><td>▁██</td></tr><tr><td>eval/precision</td><td>▁█▄</td></tr><tr><td>eval/recall</td><td>█▁█</td></tr><tr><td>eval/runtime</td><td>▇▁█</td></tr><tr><td>eval/samples_per_second</td><td>▂█▁</td></tr><tr><td>eval/steps_per_second</td><td>▂█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92243</td></tr><tr><td>eval/f1</td><td>0.91679</td></tr><tr><td>eval/loss</td><td>0.32559</td></tr><tr><td>eval/precision</td><td>0.93752</td></tr><tr><td>eval/recall</td><td>0.89696</td></tr><tr><td>eval/runtime</td><td>7.3891</td></tr><tr><td>eval/samples_per_second</td><td>774.652</td></tr><tr><td>eval/steps_per_second</td><td>96.899</td></tr><tr><td>total_flos</td><td>2274630819171840.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "You can sync this run to the cloud by running:<br><code>wandb sync /content/wandb/offline-run-20251216_184625-na7h5i8i<code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/offline-run-20251216_184625-na7h5i8i/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20251216_185142-rym6dw1t</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='84' max='1432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  84/1432 00:07 < 02:06, 10.67 it/s, Epoch 0.12/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training started...\")\n",
        "trainer.train()\n",
        "print(\"Training completed.\")"
      ],
      "metadata": {
        "id": "7M6ctpR14KZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valutazione sul test set\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "print(f\"Loss: {eval_results['eval_loss']:.4f}\")"
      ],
      "metadata": {
        "id": "0_aqclgj4OQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sarcasm_bert(text):\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    score = probs[0][1].item()\n",
        "    prediction = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    label = \"SARCASTIC\" if prediction == 1 else \"NON SARCASTIC\"\n",
        "    return label, score\n",
        "\n",
        "# Examples\n",
        "sample_1 = \"Local man discovers water is wet\"\n",
        "sample_2 = \"My favorite hobby is sitting in a two-hour meeting that could have been a single sentence email.\"\n",
        "sample_3 = \"Politician promises to fix everything in 24 hours\"\n",
        "\n",
        "print(f\"'{sample_1}' -> {predict_sarcasm_bert(sample_1)}\")\n",
        "print(f\"'{sample_2}' -> {predict_sarcasm_bert(sample_2)}\")\n",
        "print(f\"'{sample_3}' -> {predict_sarcasm_bert(sample_3)}\")"
      ],
      "metadata": {
        "id": "wpwz3Pwr4ReQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "print(\"Ricalcolo metriche Baseline...\")\n",
        "lr_model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "lr_preds = lr_model.predict(X_test_tfidf)\n",
        "\n",
        "baseline_acc = accuracy_score(y_test, lr_preds)\n",
        "baseline_f1 = f1_score(y_test, lr_preds)\n",
        "\n",
        "print(\"Recupero metriche DistilBERT...\")\n",
        "# Usiamo il trainer per fare predizioni sull'intero test set\n",
        "bert_output = trainer.predict(tokenized_test)\n",
        "bert_preds = np.argmax(bert_output.predictions, axis=1)\n",
        "bert_labels = bert_output.label_ids\n",
        "\n",
        "bert_acc = accuracy_score(bert_labels, bert_preds)\n",
        "bert_f1 = f1_score(bert_labels, bert_preds)\n",
        "\n",
        "\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Modello': ['Baseline (LogReg)', 'DistilBERT', 'Baseline (LogReg)', 'DistilBERT'],\n",
        "    'Metrica': ['Accuracy', 'Accuracy', 'F1 Score', 'F1 Score'],\n",
        "    'Valore': [baseline_acc, bert_acc, baseline_f1, bert_f1]\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Metrica', y='Valore', hue='Modello', data=metrics_df, palette=\"viridis\")\n",
        "plt.title('Confronto Performance: Baseline vs SOTA')\n",
        "plt.ylim(0.7, 1.0)\n",
        "plt.ylabel('Score')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Miglioramento Accuracy: +{(bert_acc - baseline_acc)*100:.2f}%\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Baseline Matrix\n",
        "sns.heatmap(confusion_matrix(y_test, lr_preds), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "ax[0].set_title(f'Baseline (Acc: {baseline_acc:.3f})')\n",
        "ax[0].set_xlabel('Predetto')\n",
        "ax[0].set_ylabel('Reale')\n",
        "\n",
        "# DistilBERT Matrix\n",
        "sns.heatmap(confusion_matrix(bert_labels, bert_preds), annot=True, fmt='d', cmap='Greens', ax=ax[1])\n",
        "ax[1].set_title(f'DistilBERT (Acc: {bert_acc:.3f})')\n",
        "ax[1].set_xlabel('Predetto')\n",
        "ax[1].set_ylabel('Reale')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "def compare_predictions(text):\n",
        "    # Baseline Prediction\n",
        "    vec = tfidf.transform([text])\n",
        "    lr_prob = lr_model.predict_proba(vec)[0][1]\n",
        "\n",
        "    # DistilBERT Prediction\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    bert_prob = torch.nn.functional.softmax(outputs.logits, dim=-1)[0][1].item()\n",
        "\n",
        "    return lr_prob, bert_prob\n",
        "\n",
        "sentences = [\n",
        "    \"Local man discovers water is wet\", # Obvious sarcasm\n",
        "    \"Government increases taxes by 5%\", # Real news\n",
        "    \"Man strictly following GPS drives car into lake\", # Context based sarcasm\n",
        "    \"Study finds that breathing is linked to staying alive\" # Logical sarcasm\n",
        "]\n",
        "\n",
        "results = []\n",
        "for s in sentences:\n",
        "    lr_p, bert_p = compare_predictions(s)\n",
        "    results.append({\n",
        "        \"Frase\": s,\n",
        "        \"Baseline (Sarcasm Prob)\": f\"{lr_p:.4f}\",\n",
        "        \"DistilBERT (Sarcasm Prob)\": f\"{bert_p:.4f}\",\n",
        "        \"Winner\": \"DistilBERT\" if abs(bert_p - (1 if lr_p < 0.5 else 0)) < abs(lr_p - (1 if lr_p < 0.5 else 0)) else \"Baseline\"\n",
        "    })\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "display(pd.DataFrame(results))"
      ],
      "metadata": {
        "id": "FYNj8CKt9AO6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}